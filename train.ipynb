{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b61b4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31217337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b154abeb-eeab-4c92-ba39-833b31bd83e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End of episode at iteration 10: \n",
      "\tEpisode reward = 10.0\n",
      "\n",
      "End of episode at iteration 37: \n",
      "\tEpisode reward = 27.0\n",
      "\n",
      "End of episode at iteration 50: \n",
      "\tEpisode reward = 13.0\n",
      "\n",
      "End of episode at iteration 59: \n",
      "\tEpisode reward = 9.0\n",
      "\n",
      "End of episode at iteration 71: \n",
      "\tEpisode reward = 12.0\n",
      "\n",
      "End of episode at iteration 103: \n",
      "\tEpisode reward = 32.0\n",
      "\n",
      "End of episode at iteration 134: \n",
      "\tEpisode reward = 31.0\n",
      "\n",
      "End of episode at iteration 162: \n",
      "\tEpisode reward = 28.0\n",
      "\n",
      "End of episode at iteration 176: \n",
      "\tEpisode reward = 14.0\n",
      "\n",
      "End of episode at iteration 203: \n",
      "\tEpisode reward = 27.0\n",
      "\n",
      "End of episode at iteration 221: \n",
      "\tEpisode reward = 18.0\n",
      "\n",
      "End of episode at iteration 240: \n",
      "\tEpisode reward = 19.0\n",
      "\n",
      "End of episode at iteration 292: \n",
      "\tEpisode reward = 52.0\n",
      "\n",
      "End of episode at iteration 323: \n",
      "\tEpisode reward = 31.0\n",
      "\n",
      "End of episode at iteration 340: \n",
      "\tEpisode reward = 17.0\n",
      "\n",
      "End of episode at iteration 357: \n",
      "\tEpisode reward = 17.0\n",
      "\n",
      "End of episode at iteration 384: \n",
      "\tEpisode reward = 27.0\n",
      "\n",
      "End of episode at iteration 399: \n",
      "\tEpisode reward = 15.0\n",
      "\n",
      "End of episode at iteration 451: \n",
      "\tEpisode reward = 52.0\n",
      "\n",
      "End of episode at iteration 469: \n",
      "\tEpisode reward = 18.0\n",
      "\n",
      "End of episode at iteration 495: \n",
      "\tEpisode reward = 26.0\n",
      "\n",
      "End of episode at iteration 511: \n",
      "\tEpisode reward = 16.0\n",
      "\n",
      "End of episode at iteration 525: \n",
      "\tEpisode reward = 14.0\n",
      "\n",
      "End of episode at iteration 547: \n",
      "\tEpisode reward = 22.0\n",
      "\n",
      "End of episode at iteration 557: \n",
      "\tEpisode reward = 10.0\n",
      "\n",
      "End of episode at iteration 575: \n",
      "\tEpisode reward = 18.0\n",
      "\n",
      "End of episode at iteration 596: \n",
      "\tEpisode reward = 21.0\n",
      "\n",
      "End of episode at iteration 612: \n",
      "\tEpisode reward = 16.0\n",
      "\n",
      "End of episode at iteration 647: \n",
      "\tEpisode reward = 35.0\n",
      "\n",
      "End of episode at iteration 671: \n",
      "\tEpisode reward = 24.0\n",
      "\n",
      "End of episode at iteration 691: \n",
      "\tEpisode reward = 20.0\n",
      "\n",
      "End of episode at iteration 709: \n",
      "\tEpisode reward = 18.0\n",
      "\n",
      "End of episode at iteration 721: \n",
      "\tEpisode reward = 12.0\n",
      "\n",
      "End of episode at iteration 736: \n",
      "\tEpisode reward = 15.0\n",
      "\n",
      "End of episode at iteration 790: \n",
      "\tEpisode reward = 54.0\n",
      "\n",
      "End of episode at iteration 821: \n",
      "\tEpisode reward = 31.0\n",
      "\n",
      "End of episode at iteration 849: \n",
      "\tEpisode reward = 28.0\n",
      "\n",
      "End of episode at iteration 870: \n",
      "\tEpisode reward = 21.0\n",
      "\n",
      "End of episode at iteration 881: \n",
      "\tEpisode reward = 11.0\n",
      "\n",
      "End of episode at iteration 913: \n",
      "\tEpisode reward = 32.0\n",
      "\n",
      "End of episode at iteration 931: \n",
      "\tEpisode reward = 18.0\n",
      "\n",
      "End of episode at iteration 966: \n",
      "\tEpisode reward = 35.0\n",
      "\n",
      "End of episode at iteration 980: \n",
      "\tEpisode reward = 14.0\n",
      "\n",
      "End of episode at iteration 994: \n",
      "\tEpisode reward = 14.0\n",
      "\n",
      "Iteration 1000: \n",
      "\tActor loss = tensor([0.7859]) \n",
      "\tCritic loss = tensor([1.0480])\n",
      "\n",
      "End of episode at iteration 1033: \n",
      "\tEpisode reward = 39.0\n",
      "\n",
      "End of episode at iteration 1061: \n",
      "\tEpisode reward = 28.0\n",
      "\n",
      "End of episode at iteration 1085: \n",
      "\tEpisode reward = 24.0\n",
      "\n",
      "End of episode at iteration 1109: \n",
      "\tEpisode reward = 24.0\n",
      "\n",
      "End of episode at iteration 1130: \n",
      "\tEpisode reward = 21.0\n",
      "\n",
      "End of episode at iteration 1144: \n",
      "\tEpisode reward = 14.0\n",
      "\n",
      "End of episode at iteration 1170: \n",
      "\tEpisode reward = 26.0\n",
      "\n",
      "End of episode at iteration 1185: \n",
      "\tEpisode reward = 15.0\n",
      "\n",
      "End of episode at iteration 1210: \n",
      "\tEpisode reward = 25.0\n",
      "\n",
      "End of episode at iteration 1230: \n",
      "\tEpisode reward = 20.0\n",
      "\n",
      "End of episode at iteration 1249: \n",
      "\tEpisode reward = 19.0\n",
      "\n",
      "End of episode at iteration 1270: \n",
      "\tEpisode reward = 21.0\n",
      "\n",
      "End of episode at iteration 1286: \n",
      "\tEpisode reward = 16.0\n",
      "\n",
      "End of episode at iteration 1347: \n",
      "\tEpisode reward = 61.0\n",
      "\n",
      "End of episode at iteration 1367: \n",
      "\tEpisode reward = 20.0\n",
      "\n",
      "End of episode at iteration 1398: \n",
      "\tEpisode reward = 31.0\n",
      "\n",
      "End of episode at iteration 1415: \n",
      "\tEpisode reward = 17.0\n",
      "\n",
      "End of episode at iteration 1432: \n",
      "\tEpisode reward = 17.0\n",
      "\n",
      "End of episode at iteration 1444: \n",
      "\tEpisode reward = 12.0\n",
      "\n",
      "End of episode at iteration 1461: \n",
      "\tEpisode reward = 17.0\n",
      "\n",
      "End of episode at iteration 1488: \n",
      "\tEpisode reward = 27.0\n",
      "\n",
      "End of episode at iteration 1509: \n",
      "\tEpisode reward = 21.0\n",
      "\n",
      "End of episode at iteration 1525: \n",
      "\tEpisode reward = 16.0\n",
      "\n",
      "End of episode at iteration 1581: \n",
      "\tEpisode reward = 56.0\n",
      "\n",
      "End of episode at iteration 1632: \n",
      "\tEpisode reward = 51.0\n",
      "\n",
      "End of episode at iteration 1644: \n",
      "\tEpisode reward = 12.0\n",
      "\n",
      "End of episode at iteration 1679: \n",
      "\tEpisode reward = 35.0\n",
      "\n",
      "End of episode at iteration 1704: \n",
      "\tEpisode reward = 25.0\n",
      "\n",
      "End of episode at iteration 1722: \n",
      "\tEpisode reward = 18.0\n",
      "\n",
      "End of episode at iteration 1739: \n",
      "\tEpisode reward = 17.0\n",
      "\n",
      "End of episode at iteration 1765: \n",
      "\tEpisode reward = 26.0\n",
      "\n",
      "End of episode at iteration 1787: \n",
      "\tEpisode reward = 22.0\n",
      "\n",
      "End of episode at iteration 1804: \n",
      "\tEpisode reward = 17.0\n",
      "\n",
      "End of episode at iteration 1815: \n",
      "\tEpisode reward = 11.0\n",
      "\n",
      "End of episode at iteration 1832: \n",
      "\tEpisode reward = 17.0\n",
      "\n",
      "End of episode at iteration 1879: \n",
      "\tEpisode reward = 47.0\n",
      "\n",
      "End of episode at iteration 1894: \n",
      "\tEpisode reward = 15.0\n",
      "\n",
      "End of episode at iteration 1915: \n",
      "\tEpisode reward = 21.0\n",
      "\n",
      "End of episode at iteration 1934: \n",
      "\tEpisode reward = 19.0\n",
      "\n",
      "End of episode at iteration 1955: \n",
      "\tEpisode reward = 21.0\n",
      "\n",
      "End of episode at iteration 1980: \n",
      "\tEpisode reward = 25.0\n",
      "\n",
      "End of episode at iteration 1995: \n",
      "\tEpisode reward = 15.0\n",
      "\n",
      "Iteration 2000: \n",
      "\tActor loss = tensor([0.5298]) \n",
      "\tCritic loss = tensor([0.5503])\n",
      "\n",
      "End of episode at iteration 2007: \n",
      "\tEpisode reward = 12.0\n",
      "\n",
      "End of episode at iteration 2018: \n",
      "\tEpisode reward = 11.0\n",
      "\n",
      "End of episode at iteration 2031: \n",
      "\tEpisode reward = 13.0\n",
      "\n",
      "End of episode at iteration 2052: \n",
      "\tEpisode reward = 21.0\n",
      "\n",
      "End of episode at iteration 2062: \n",
      "\tEpisode reward = 10.0\n",
      "\n",
      "End of episode at iteration 2076: \n",
      "\tEpisode reward = 14.0\n",
      "\n",
      "End of episode at iteration 2093: \n",
      "\tEpisode reward = 17.0\n",
      "\n",
      "End of episode at iteration 2115: \n",
      "\tEpisode reward = 22.0\n",
      "\n",
      "End of episode at iteration 2135: \n",
      "\tEpisode reward = 20.0\n",
      "\n",
      "End of episode at iteration 2197: \n",
      "\tEpisode reward = 62.0\n",
      "\n",
      "End of episode at iteration 2242: \n",
      "\tEpisode reward = 45.0\n",
      "\n",
      "End of episode at iteration 2291: \n",
      "\tEpisode reward = 49.0\n",
      "\n",
      "End of episode at iteration 2319: \n",
      "\tEpisode reward = 28.0\n",
      "\n",
      "End of episode at iteration 2339: \n",
      "\tEpisode reward = 20.0\n",
      "\n",
      "End of episode at iteration 2369: \n",
      "\tEpisode reward = 30.0\n",
      "\n",
      "End of episode at iteration 2389: \n",
      "\tEpisode reward = 20.0\n",
      "\n",
      "End of episode at iteration 2417: \n",
      "\tEpisode reward = 28.0\n",
      "\n",
      "End of episode at iteration 2440: \n",
      "\tEpisode reward = 23.0\n",
      "\n",
      "End of episode at iteration 2463: \n",
      "\tEpisode reward = 23.0\n",
      "\n",
      "End of episode at iteration 2491: \n",
      "\tEpisode reward = 28.0\n",
      "\n",
      "End of episode at iteration 2517: \n",
      "\tEpisode reward = 26.0\n",
      "\n",
      "End of episode at iteration 2536: \n",
      "\tEpisode reward = 19.0\n",
      "\n",
      "End of episode at iteration 2569: \n",
      "\tEpisode reward = 33.0\n",
      "\n",
      "End of episode at iteration 2622: \n",
      "\tEpisode reward = 53.0\n",
      "\n",
      "End of episode at iteration 2636: \n",
      "\tEpisode reward = 14.0\n",
      "\n",
      "End of episode at iteration 2657: \n",
      "\tEpisode reward = 21.0\n",
      "\n",
      "End of episode at iteration 2695: \n",
      "\tEpisode reward = 38.0\n",
      "\n",
      "End of episode at iteration 2714: \n",
      "\tEpisode reward = 19.0\n",
      "\n",
      "End of episode at iteration 2727: \n",
      "\tEpisode reward = 13.0\n",
      "\n",
      "End of episode at iteration 2746: \n",
      "\tEpisode reward = 19.0\n",
      "\n",
      "End of episode at iteration 2766: \n",
      "\tEpisode reward = 20.0\n",
      "\n",
      "End of episode at iteration 2798: \n",
      "\tEpisode reward = 32.0\n",
      "\n",
      "End of episode at iteration 2830: \n",
      "\tEpisode reward = 32.0\n",
      "\n",
      "End of episode at iteration 2858: \n",
      "\tEpisode reward = 28.0\n",
      "\n",
      "End of episode at iteration 2868: \n",
      "\tEpisode reward = 10.0\n",
      "\n",
      "End of episode at iteration 2897: \n",
      "\tEpisode reward = 29.0\n",
      "\n",
      "End of episode at iteration 2915: \n",
      "\tEpisode reward = 18.0\n",
      "\n",
      "End of episode at iteration 2935: \n",
      "\tEpisode reward = 20.0\n",
      "\n",
      "End of episode at iteration 2966: \n",
      "\tEpisode reward = 31.0\n",
      "\n",
      "End of episode at iteration 2987: \n",
      "\tEpisode reward = 21.0\n",
      "\n",
      "Iteration 3000: \n",
      "\tActor loss = tensor([0.7693]) \n",
      "\tCritic loss = tensor([0.9394])\n",
      "\n",
      "End of episode at iteration 3021: \n",
      "\tEpisode reward = 34.0\n",
      "\n",
      "End of episode at iteration 3053: \n",
      "\tEpisode reward = 32.0\n",
      "\n",
      "End of episode at iteration 3090: \n",
      "\tEpisode reward = 37.0\n",
      "\n",
      "End of episode at iteration 3111: \n",
      "\tEpisode reward = 21.0\n",
      "\n",
      "End of episode at iteration 3123: \n",
      "\tEpisode reward = 12.0\n",
      "\n",
      "End of episode at iteration 3162: \n",
      "\tEpisode reward = 39.0\n",
      "\n",
      "End of episode at iteration 3283: \n",
      "\tEpisode reward = 121.0\n",
      "\n",
      "End of episode at iteration 3309: \n",
      "\tEpisode reward = 26.0\n",
      "\n",
      "End of episode at iteration 3343: \n",
      "\tEpisode reward = 34.0\n",
      "\n",
      "End of episode at iteration 3372: \n",
      "\tEpisode reward = 29.0\n",
      "\n",
      "End of episode at iteration 3413: \n",
      "\tEpisode reward = 41.0\n",
      "\n",
      "End of episode at iteration 3438: \n",
      "\tEpisode reward = 25.0\n",
      "\n",
      "End of episode at iteration 3487: \n",
      "\tEpisode reward = 49.0\n",
      "\n",
      "End of episode at iteration 3507: \n",
      "\tEpisode reward = 20.0\n",
      "\n",
      "End of episode at iteration 3525: \n",
      "\tEpisode reward = 18.0\n",
      "\n",
      "End of episode at iteration 3538: \n",
      "\tEpisode reward = 13.0\n",
      "\n",
      "End of episode at iteration 3561: \n",
      "\tEpisode reward = 23.0\n",
      "\n",
      "End of episode at iteration 3584: \n",
      "\tEpisode reward = 23.0\n",
      "\n",
      "End of episode at iteration 3600: \n",
      "\tEpisode reward = 16.0\n",
      "\n",
      "End of episode at iteration 3619: \n",
      "\tEpisode reward = 19.0\n",
      "\n",
      "End of episode at iteration 3668: \n",
      "\tEpisode reward = 49.0\n",
      "\n",
      "End of episode at iteration 3681: \n",
      "\tEpisode reward = 13.0\n",
      "\n",
      "End of episode at iteration 3693: \n",
      "\tEpisode reward = 12.0\n",
      "\n",
      "End of episode at iteration 3710: \n",
      "\tEpisode reward = 17.0\n",
      "\n",
      "End of episode at iteration 3735: \n",
      "\tEpisode reward = 25.0\n",
      "\n",
      "End of episode at iteration 3751: \n",
      "\tEpisode reward = 16.0\n",
      "\n",
      "End of episode at iteration 3777: \n",
      "\tEpisode reward = 26.0\n",
      "\n",
      "End of episode at iteration 3802: \n",
      "\tEpisode reward = 25.0\n",
      "\n",
      "End of episode at iteration 3889: \n",
      "\tEpisode reward = 87.0\n",
      "\n",
      "End of episode at iteration 3951: \n",
      "\tEpisode reward = 62.0\n",
      "\n",
      "Iteration 4000: \n",
      "\tActor loss = tensor([0.5459]) \n",
      "\tCritic loss = tensor([0.9316])\n",
      "\n",
      "End of episode at iteration 4005: \n",
      "\tEpisode reward = 54.0\n",
      "\n",
      "End of episode at iteration 4019: \n",
      "\tEpisode reward = 14.0\n",
      "\n",
      "End of episode at iteration 4033: \n",
      "\tEpisode reward = 14.0\n",
      "\n",
      "End of episode at iteration 4061: \n",
      "\tEpisode reward = 28.0\n",
      "\n",
      "End of episode at iteration 4084: \n",
      "\tEpisode reward = 23.0\n",
      "\n",
      "End of episode at iteration 4134: \n",
      "\tEpisode reward = 50.0\n",
      "\n",
      "End of episode at iteration 4184: \n",
      "\tEpisode reward = 50.0\n",
      "\n",
      "End of episode at iteration 4217: \n",
      "\tEpisode reward = 33.0\n",
      "\n",
      "End of episode at iteration 4265: \n",
      "\tEpisode reward = 48.0\n",
      "\n",
      "End of episode at iteration 4281: \n",
      "\tEpisode reward = 16.0\n",
      "\n",
      "End of episode at iteration 4357: \n",
      "\tEpisode reward = 76.0\n",
      "\n",
      "End of episode at iteration 4378: \n",
      "\tEpisode reward = 21.0\n",
      "\n",
      "End of episode at iteration 4396: \n",
      "\tEpisode reward = 18.0\n",
      "\n",
      "End of episode at iteration 4473: \n",
      "\tEpisode reward = 77.0\n",
      "\n",
      "End of episode at iteration 4500: \n",
      "\tEpisode reward = 27.0\n",
      "\n",
      "End of episode at iteration 4560: \n",
      "\tEpisode reward = 60.0\n",
      "\n",
      "End of episode at iteration 4582: \n",
      "\tEpisode reward = 22.0\n",
      "\n",
      "End of episode at iteration 4610: \n",
      "\tEpisode reward = 28.0\n",
      "\n",
      "End of episode at iteration 4664: \n",
      "\tEpisode reward = 54.0\n",
      "\n",
      "End of episode at iteration 4683: \n",
      "\tEpisode reward = 19.0\n",
      "\n",
      "End of episode at iteration 4702: \n",
      "\tEpisode reward = 19.0\n",
      "\n",
      "End of episode at iteration 4726: \n",
      "\tEpisode reward = 24.0\n",
      "\n",
      "End of episode at iteration 4740: \n",
      "\tEpisode reward = 14.0\n",
      "\n",
      "End of episode at iteration 4784: \n",
      "\tEpisode reward = 44.0\n",
      "\n",
      "End of episode at iteration 4833: \n",
      "\tEpisode reward = 49.0\n",
      "\n",
      "End of episode at iteration 4875: \n",
      "\tEpisode reward = 42.0\n",
      "\n",
      "End of episode at iteration 4890: \n",
      "\tEpisode reward = 15.0\n",
      "\n",
      "End of episode at iteration 4923: \n",
      "\tEpisode reward = 33.0\n",
      "\n",
      "End of episode at iteration 4939: \n",
      "\tEpisode reward = 16.0\n",
      "\n",
      "End of episode at iteration 4955: \n",
      "\tEpisode reward = 16.0\n",
      "\n",
      "End of episode at iteration 4974: \n",
      "\tEpisode reward = 19.0\n",
      "\n",
      "Iteration 5000: \n",
      "\tActor loss = tensor([0.5716]) \n",
      "\tCritic loss = tensor([0.8217])\n",
      "\n",
      "End of episode at iteration 5026: \n",
      "\tEpisode reward = 52.0\n",
      "\n",
      "End of episode at iteration 5107: \n",
      "\tEpisode reward = 81.0\n",
      "\n",
      "End of episode at iteration 5123: \n",
      "\tEpisode reward = 16.0\n",
      "\n",
      "End of episode at iteration 5151: \n",
      "\tEpisode reward = 28.0\n",
      "\n",
      "End of episode at iteration 5177: \n",
      "\tEpisode reward = 26.0\n",
      "\n",
      "End of episode at iteration 5201: \n",
      "\tEpisode reward = 24.0\n",
      "\n",
      "End of episode at iteration 5221: \n",
      "\tEpisode reward = 20.0\n",
      "\n",
      "End of episode at iteration 5305: \n",
      "\tEpisode reward = 84.0\n",
      "\n",
      "End of episode at iteration 5335: \n",
      "\tEpisode reward = 30.0\n",
      "\n",
      "End of episode at iteration 5358: \n",
      "\tEpisode reward = 23.0\n",
      "\n",
      "End of episode at iteration 5402: \n",
      "\tEpisode reward = 44.0\n",
      "\n",
      "End of episode at iteration 5421: \n",
      "\tEpisode reward = 19.0\n",
      "\n",
      "End of episode at iteration 5437: \n",
      "\tEpisode reward = 16.0\n",
      "\n",
      "End of episode at iteration 5467: \n",
      "\tEpisode reward = 30.0\n",
      "\n",
      "End of episode at iteration 5495: \n",
      "\tEpisode reward = 28.0\n",
      "\n",
      "End of episode at iteration 5520: \n",
      "\tEpisode reward = 25.0\n",
      "\n",
      "End of episode at iteration 5543: \n",
      "\tEpisode reward = 23.0\n",
      "\n",
      "End of episode at iteration 5565: \n",
      "\tEpisode reward = 22.0\n",
      "\n",
      "End of episode at iteration 5593: \n",
      "\tEpisode reward = 28.0\n",
      "\n",
      "End of episode at iteration 5641: \n",
      "\tEpisode reward = 48.0\n",
      "\n",
      "End of episode at iteration 5664: \n",
      "\tEpisode reward = 23.0\n",
      "\n",
      "End of episode at iteration 5701: \n",
      "\tEpisode reward = 37.0\n",
      "\n",
      "End of episode at iteration 5752: \n",
      "\tEpisode reward = 51.0\n",
      "\n",
      "End of episode at iteration 5771: \n",
      "\tEpisode reward = 19.0\n",
      "\n",
      "End of episode at iteration 5820: \n",
      "\tEpisode reward = 49.0\n",
      "\n",
      "End of episode at iteration 5837: \n",
      "\tEpisode reward = 17.0\n",
      "\n",
      "End of episode at iteration 5849: \n",
      "\tEpisode reward = 12.0\n",
      "\n",
      "End of episode at iteration 5865: \n",
      "\tEpisode reward = 16.0\n",
      "\n",
      "End of episode at iteration 5902: \n",
      "\tEpisode reward = 37.0\n",
      "\n",
      "End of episode at iteration 5938: \n",
      "\tEpisode reward = 36.0\n",
      "\n",
      "End of episode at iteration 5964: \n",
      "\tEpisode reward = 26.0\n",
      "\n",
      "End of episode at iteration 5994: \n",
      "\tEpisode reward = 30.0\n",
      "\n",
      "Iteration 6000: \n",
      "\tActor loss = tensor([0.7125]) \n",
      "\tCritic loss = tensor([0.7097])\n",
      "\n",
      "End of episode at iteration 6047: \n",
      "\tEpisode reward = 53.0\n",
      "\n",
      "End of episode at iteration 6107: \n",
      "\tEpisode reward = 60.0\n",
      "\n",
      "End of episode at iteration 6121: \n",
      "\tEpisode reward = 14.0\n",
      "\n",
      "End of episode at iteration 6149: \n",
      "\tEpisode reward = 28.0\n",
      "\n",
      "End of episode at iteration 6212: \n",
      "\tEpisode reward = 63.0\n",
      "\n",
      "End of episode at iteration 6258: \n",
      "\tEpisode reward = 46.0\n",
      "\n",
      "End of episode at iteration 6272: \n",
      "\tEpisode reward = 14.0\n",
      "\n",
      "End of episode at iteration 6303: \n",
      "\tEpisode reward = 31.0\n",
      "\n",
      "End of episode at iteration 6317: \n",
      "\tEpisode reward = 14.0\n",
      "\n",
      "End of episode at iteration 6353: \n",
      "\tEpisode reward = 36.0\n",
      "\n",
      "End of episode at iteration 6368: \n",
      "\tEpisode reward = 15.0\n",
      "\n",
      "End of episode at iteration 6382: \n",
      "\tEpisode reward = 14.0\n",
      "\n",
      "End of episode at iteration 6403: \n",
      "\tEpisode reward = 21.0\n",
      "\n",
      "End of episode at iteration 6444: \n",
      "\tEpisode reward = 41.0\n",
      "\n",
      "End of episode at iteration 6479: \n",
      "\tEpisode reward = 35.0\n",
      "\n",
      "End of episode at iteration 6500: \n",
      "\tEpisode reward = 21.0\n",
      "\n",
      "End of episode at iteration 6527: \n",
      "\tEpisode reward = 27.0\n",
      "\n",
      "End of episode at iteration 6556: \n",
      "\tEpisode reward = 29.0\n",
      "\n",
      "End of episode at iteration 6593: \n",
      "\tEpisode reward = 37.0\n",
      "\n",
      "End of episode at iteration 6618: \n",
      "\tEpisode reward = 25.0\n",
      "\n",
      "End of episode at iteration 6719: \n",
      "\tEpisode reward = 101.0\n",
      "\n",
      "End of episode at iteration 6764: \n",
      "\tEpisode reward = 45.0\n",
      "\n",
      "End of episode at iteration 6788: \n",
      "\tEpisode reward = 24.0\n",
      "\n",
      "End of episode at iteration 6816: \n",
      "\tEpisode reward = 28.0\n",
      "\n",
      "End of episode at iteration 6838: \n",
      "\tEpisode reward = 22.0\n",
      "\n",
      "End of episode at iteration 6865: \n",
      "\tEpisode reward = 27.0\n",
      "\n",
      "End of episode at iteration 6876: \n",
      "\tEpisode reward = 11.0\n",
      "\n",
      "End of episode at iteration 6891: \n",
      "\tEpisode reward = 15.0\n",
      "\n",
      "End of episode at iteration 6921: \n",
      "\tEpisode reward = 30.0\n",
      "\n",
      "Iteration 7000: \n",
      "\tActor loss = tensor([0.1191]) \n",
      "\tCritic loss = tensor([0.1241])\n",
      "\n",
      "End of episode at iteration 7003: \n",
      "\tEpisode reward = 82.0\n",
      "\n",
      "End of episode at iteration 7029: \n",
      "\tEpisode reward = 26.0\n",
      "\n",
      "End of episode at iteration 7074: \n",
      "\tEpisode reward = 45.0\n",
      "\n",
      "End of episode at iteration 7088: \n",
      "\tEpisode reward = 14.0\n",
      "\n",
      "End of episode at iteration 7128: \n",
      "\tEpisode reward = 40.0\n",
      "\n",
      "End of episode at iteration 7210: \n",
      "\tEpisode reward = 82.0\n",
      "\n",
      "End of episode at iteration 7228: \n",
      "\tEpisode reward = 18.0\n",
      "\n",
      "End of episode at iteration 7268: \n",
      "\tEpisode reward = 40.0\n",
      "\n",
      "End of episode at iteration 7288: \n",
      "\tEpisode reward = 20.0\n",
      "\n",
      "End of episode at iteration 7334: \n",
      "\tEpisode reward = 46.0\n",
      "\n",
      "End of episode at iteration 7349: \n",
      "\tEpisode reward = 15.0\n",
      "\n",
      "End of episode at iteration 7367: \n",
      "\tEpisode reward = 18.0\n",
      "\n",
      "End of episode at iteration 7393: \n",
      "\tEpisode reward = 26.0\n",
      "\n",
      "End of episode at iteration 7432: \n",
      "\tEpisode reward = 39.0\n",
      "\n",
      "End of episode at iteration 7503: \n",
      "\tEpisode reward = 71.0\n",
      "\n",
      "End of episode at iteration 7521: \n",
      "\tEpisode reward = 18.0\n",
      "\n",
      "End of episode at iteration 7580: \n",
      "\tEpisode reward = 59.0\n",
      "\n",
      "End of episode at iteration 7607: \n",
      "\tEpisode reward = 27.0\n",
      "\n",
      "End of episode at iteration 7667: \n",
      "\tEpisode reward = 60.0\n",
      "\n",
      "End of episode at iteration 7704: \n",
      "\tEpisode reward = 37.0\n",
      "\n",
      "End of episode at iteration 7745: \n",
      "\tEpisode reward = 41.0\n",
      "\n",
      "End of episode at iteration 7771: \n",
      "\tEpisode reward = 26.0\n",
      "\n",
      "End of episode at iteration 7801: \n",
      "\tEpisode reward = 30.0\n",
      "\n",
      "End of episode at iteration 7841: \n",
      "\tEpisode reward = 40.0\n",
      "\n",
      "End of episode at iteration 7914: \n",
      "\tEpisode reward = 73.0\n",
      "\n",
      "End of episode at iteration 7937: \n",
      "\tEpisode reward = 23.0\n",
      "\n",
      "End of episode at iteration 7971: \n",
      "\tEpisode reward = 34.0\n",
      "\n",
      "End of episode at iteration 7988: \n",
      "\tEpisode reward = 17.0\n",
      "\n",
      "Iteration 8000: \n",
      "\tActor loss = tensor([0.2081]) \n",
      "\tCritic loss = tensor([0.1025])\n",
      "\n",
      "End of episode at iteration 8022: \n",
      "\tEpisode reward = 34.0\n",
      "\n",
      "End of episode at iteration 8055: \n",
      "\tEpisode reward = 33.0\n",
      "\n",
      "End of episode at iteration 8100: \n",
      "\tEpisode reward = 45.0\n",
      "\n",
      "End of episode at iteration 8122: \n",
      "\tEpisode reward = 22.0\n",
      "\n",
      "End of episode at iteration 8235: \n",
      "\tEpisode reward = 113.0\n",
      "\n",
      "End of episode at iteration 8257: \n",
      "\tEpisode reward = 22.0\n",
      "\n",
      "End of episode at iteration 8337: \n",
      "\tEpisode reward = 80.0\n",
      "\n",
      "End of episode at iteration 8359: \n",
      "\tEpisode reward = 22.0\n",
      "\n",
      "End of episode at iteration 8375: \n",
      "\tEpisode reward = 16.0\n",
      "\n",
      "End of episode at iteration 8394: \n",
      "\tEpisode reward = 19.0\n",
      "\n",
      "End of episode at iteration 8452: \n",
      "\tEpisode reward = 58.0\n",
      "\n",
      "End of episode at iteration 8478: \n",
      "\tEpisode reward = 26.0\n",
      "\n",
      "End of episode at iteration 8521: \n",
      "\tEpisode reward = 43.0\n",
      "\n",
      "End of episode at iteration 8536: \n",
      "\tEpisode reward = 15.0\n",
      "\n",
      "End of episode at iteration 8558: \n",
      "\tEpisode reward = 22.0\n",
      "\n",
      "End of episode at iteration 8595: \n",
      "\tEpisode reward = 37.0\n",
      "\n",
      "End of episode at iteration 8645: \n",
      "\tEpisode reward = 50.0\n",
      "\n",
      "End of episode at iteration 8682: \n",
      "\tEpisode reward = 37.0\n",
      "\n",
      "End of episode at iteration 8706: \n",
      "\tEpisode reward = 24.0\n",
      "\n",
      "End of episode at iteration 8764: \n",
      "\tEpisode reward = 58.0\n",
      "\n",
      "End of episode at iteration 8812: \n",
      "\tEpisode reward = 48.0\n",
      "\n",
      "End of episode at iteration 8823: \n",
      "\tEpisode reward = 11.0\n",
      "\n",
      "End of episode at iteration 8871: \n",
      "\tEpisode reward = 48.0\n",
      "\n",
      "End of episode at iteration 8930: \n",
      "\tEpisode reward = 59.0\n",
      "\n",
      "End of episode at iteration 8943: \n",
      "\tEpisode reward = 13.0\n",
      "\n",
      "End of episode at iteration 8978: \n",
      "\tEpisode reward = 35.0\n",
      "\n",
      "Iteration 9000: \n",
      "\tActor loss = tensor([0.6525]) \n",
      "\tCritic loss = tensor([0.7274])\n",
      "\n",
      "End of episode at iteration 9022: \n",
      "\tEpisode reward = 44.0\n",
      "\n",
      "End of episode at iteration 9045: \n",
      "\tEpisode reward = 23.0\n",
      "\n",
      "End of episode at iteration 9071: \n",
      "\tEpisode reward = 26.0\n",
      "\n",
      "End of episode at iteration 9084: \n",
      "\tEpisode reward = 13.0\n",
      "\n",
      "End of episode at iteration 9110: \n",
      "\tEpisode reward = 26.0\n",
      "\n",
      "End of episode at iteration 9151: \n",
      "\tEpisode reward = 41.0\n",
      "\n",
      "End of episode at iteration 9179: \n",
      "\tEpisode reward = 28.0\n",
      "\n",
      "End of episode at iteration 9193: \n",
      "\tEpisode reward = 14.0\n",
      "\n",
      "End of episode at iteration 9347: \n",
      "\tEpisode reward = 154.0\n",
      "\n",
      "End of episode at iteration 9449: \n",
      "\tEpisode reward = 102.0\n",
      "\n",
      "End of episode at iteration 9472: \n",
      "\tEpisode reward = 23.0\n",
      "\n",
      "End of episode at iteration 9515: \n",
      "\tEpisode reward = 43.0\n",
      "\n",
      "End of episode at iteration 9549: \n",
      "\tEpisode reward = 34.0\n",
      "\n",
      "End of episode at iteration 9602: \n",
      "\tEpisode reward = 53.0\n",
      "\n",
      "End of episode at iteration 9631: \n",
      "\tEpisode reward = 29.0\n",
      "\n",
      "End of episode at iteration 9661: \n",
      "\tEpisode reward = 30.0\n",
      "\n",
      "End of episode at iteration 9680: \n",
      "\tEpisode reward = 19.0\n",
      "\n",
      "End of episode at iteration 9725: \n",
      "\tEpisode reward = 45.0\n",
      "\n",
      "End of episode at iteration 9789: \n",
      "\tEpisode reward = 64.0\n",
      "\n",
      "End of episode at iteration 9876: \n",
      "\tEpisode reward = 87.0\n",
      "\n",
      "End of episode at iteration 9938: \n",
      "\tEpisode reward = 62.0\n",
      "\n",
      "End of episode at iteration 9951: \n",
      "\tEpisode reward = 13.0\n",
      "\n",
      "End of episode at iteration 9971: \n",
      "\tEpisode reward = 20.0\n",
      "\n",
      "Iteration 10000: \n",
      "\tActor loss = tensor([0.5509]) \n",
      "\tCritic loss = tensor([0.6787])\n",
      "\n",
      "End of episode at iteration 10021: \n",
      "\tEpisode reward = 50.0\n",
      "\n",
      "End of episode at iteration 10058: \n",
      "\tEpisode reward = 37.0\n",
      "\n",
      "End of episode at iteration 10176: \n",
      "\tEpisode reward = 118.0\n",
      "\n",
      "End of episode at iteration 10195: \n",
      "\tEpisode reward = 19.0\n",
      "\n",
      "End of episode at iteration 10233: \n",
      "\tEpisode reward = 38.0\n",
      "\n",
      "End of episode at iteration 10265: \n",
      "\tEpisode reward = 32.0\n",
      "\n",
      "End of episode at iteration 10309: \n",
      "\tEpisode reward = 44.0\n",
      "\n",
      "End of episode at iteration 10327: \n",
      "\tEpisode reward = 18.0\n",
      "\n",
      "End of episode at iteration 10362: \n",
      "\tEpisode reward = 35.0\n",
      "\n",
      "End of episode at iteration 10403: \n",
      "\tEpisode reward = 41.0\n",
      "\n",
      "End of episode at iteration 10456: \n",
      "\tEpisode reward = 53.0\n",
      "\n",
      "End of episode at iteration 10469: \n",
      "\tEpisode reward = 13.0\n",
      "\n",
      "End of episode at iteration 10488: \n",
      "\tEpisode reward = 19.0\n",
      "\n",
      "End of episode at iteration 10542: \n",
      "\tEpisode reward = 54.0\n",
      "\n",
      "End of episode at iteration 10609: \n",
      "\tEpisode reward = 67.0\n",
      "\n",
      "End of episode at iteration 10629: \n",
      "\tEpisode reward = 20.0\n",
      "\n",
      "End of episode at iteration 10643: \n",
      "\tEpisode reward = 14.0\n",
      "\n",
      "End of episode at iteration 10656: \n",
      "\tEpisode reward = 13.0\n",
      "\n",
      "End of episode at iteration 10695: \n",
      "\tEpisode reward = 39.0\n",
      "\n",
      "End of episode at iteration 10718: \n",
      "\tEpisode reward = 23.0\n",
      "\n",
      "End of episode at iteration 10751: \n",
      "\tEpisode reward = 33.0\n",
      "\n",
      "End of episode at iteration 10793: \n",
      "\tEpisode reward = 42.0\n",
      "\n",
      "End of episode at iteration 10836: \n",
      "\tEpisode reward = 43.0\n",
      "\n",
      "End of episode at iteration 10852: \n",
      "\tEpisode reward = 16.0\n",
      "\n",
      "End of episode at iteration 10982: \n",
      "\tEpisode reward = 130.0\n",
      "\n",
      "Iteration 11000: \n",
      "\tActor loss = tensor([-0.1565]) \n",
      "\tCritic loss = tensor([0.5220])\n",
      "\n",
      "End of episode at iteration 11003: \n",
      "\tEpisode reward = 21.0\n",
      "\n",
      "End of episode at iteration 11035: \n",
      "\tEpisode reward = 32.0\n",
      "\n",
      "End of episode at iteration 11064: \n",
      "\tEpisode reward = 29.0\n",
      "\n",
      "End of episode at iteration 11085: \n",
      "\tEpisode reward = 21.0\n",
      "\n",
      "End of episode at iteration 11149: \n",
      "\tEpisode reward = 64.0\n",
      "\n",
      "End of episode at iteration 11178: \n",
      "\tEpisode reward = 29.0\n",
      "\n",
      "End of episode at iteration 11221: \n",
      "\tEpisode reward = 43.0\n",
      "\n",
      "End of episode at iteration 11266: \n",
      "\tEpisode reward = 45.0\n",
      "\n",
      "End of episode at iteration 11289: \n",
      "\tEpisode reward = 23.0\n",
      "\n",
      "End of episode at iteration 11346: \n",
      "\tEpisode reward = 57.0\n",
      "\n",
      "End of episode at iteration 11406: \n",
      "\tEpisode reward = 60.0\n",
      "\n",
      "End of episode at iteration 11479: \n",
      "\tEpisode reward = 73.0\n",
      "\n",
      "End of episode at iteration 11523: \n",
      "\tEpisode reward = 44.0\n",
      "\n",
      "End of episode at iteration 11581: \n",
      "\tEpisode reward = 58.0\n",
      "\n",
      "End of episode at iteration 11638: \n",
      "\tEpisode reward = 57.0\n",
      "\n",
      "End of episode at iteration 11654: \n",
      "\tEpisode reward = 16.0\n",
      "\n",
      "End of episode at iteration 11716: \n",
      "\tEpisode reward = 62.0\n",
      "\n",
      "End of episode at iteration 11792: \n",
      "\tEpisode reward = 76.0\n",
      "\n",
      "End of episode at iteration 11902: \n",
      "\tEpisode reward = 110.0\n",
      "\n",
      "End of episode at iteration 11961: \n",
      "\tEpisode reward = 59.0\n",
      "\n",
      "Iteration 12000: \n",
      "\tActor loss = tensor([0.3351]) \n",
      "\tCritic loss = tensor([0.9421])\n",
      "\n",
      "End of episode at iteration 12013: \n",
      "\tEpisode reward = 52.0\n",
      "\n",
      "End of episode at iteration 12044: \n",
      "\tEpisode reward = 31.0\n",
      "\n",
      "End of episode at iteration 12094: \n",
      "\tEpisode reward = 50.0\n",
      "\n",
      "End of episode at iteration 12111: \n",
      "\tEpisode reward = 17.0\n",
      "\n",
      "End of episode at iteration 12164: \n",
      "\tEpisode reward = 53.0\n",
      "\n",
      "End of episode at iteration 12206: \n",
      "\tEpisode reward = 42.0\n",
      "\n",
      "End of episode at iteration 12280: \n",
      "\tEpisode reward = 74.0\n",
      "\n",
      "End of episode at iteration 12314: \n",
      "\tEpisode reward = 34.0\n",
      "\n",
      "End of episode at iteration 12376: \n",
      "\tEpisode reward = 62.0\n",
      "\n",
      "End of episode at iteration 12406: \n",
      "\tEpisode reward = 30.0\n",
      "\n",
      "End of episode at iteration 12437: \n",
      "\tEpisode reward = 31.0\n",
      "\n",
      "End of episode at iteration 12489: \n",
      "\tEpisode reward = 52.0\n",
      "\n",
      "End of episode at iteration 12515: \n",
      "\tEpisode reward = 26.0\n",
      "\n",
      "End of episode at iteration 12583: \n",
      "\tEpisode reward = 68.0\n",
      "\n",
      "End of episode at iteration 12639: \n",
      "\tEpisode reward = 56.0\n",
      "\n",
      "End of episode at iteration 12657: \n",
      "\tEpisode reward = 18.0\n",
      "\n",
      "End of episode at iteration 12678: \n",
      "\tEpisode reward = 21.0\n",
      "\n",
      "End of episode at iteration 12724: \n",
      "\tEpisode reward = 46.0\n",
      "\n",
      "End of episode at iteration 12753: \n",
      "\tEpisode reward = 29.0\n",
      "\n",
      "End of episode at iteration 12778: \n",
      "\tEpisode reward = 25.0\n",
      "\n",
      "End of episode at iteration 12874: \n",
      "\tEpisode reward = 96.0\n",
      "\n",
      "End of episode at iteration 12915: \n",
      "\tEpisode reward = 41.0\n",
      "\n",
      "End of episode at iteration 12962: \n",
      "\tEpisode reward = 47.0\n",
      "\n",
      "End of episode at iteration 12996: \n",
      "\tEpisode reward = 34.0\n",
      "\n",
      "Iteration 13000: \n",
      "\tActor loss = tensor([0.3362]) \n",
      "\tCritic loss = tensor([0.4522])\n",
      "\n",
      "End of episode at iteration 13026: \n",
      "\tEpisode reward = 30.0\n",
      "\n",
      "End of episode at iteration 13049: \n",
      "\tEpisode reward = 23.0\n",
      "\n",
      "End of episode at iteration 13124: \n",
      "\tEpisode reward = 75.0\n",
      "\n",
      "End of episode at iteration 13167: \n",
      "\tEpisode reward = 43.0\n",
      "\n",
      "End of episode at iteration 13189: \n",
      "\tEpisode reward = 22.0\n",
      "\n",
      "End of episode at iteration 13219: \n",
      "\tEpisode reward = 30.0\n",
      "\n",
      "End of episode at iteration 13244: \n",
      "\tEpisode reward = 25.0\n",
      "\n",
      "End of episode at iteration 13303: \n",
      "\tEpisode reward = 59.0\n",
      "\n",
      "End of episode at iteration 13399: \n",
      "\tEpisode reward = 96.0\n",
      "\n",
      "End of episode at iteration 13466: \n",
      "\tEpisode reward = 67.0\n",
      "\n",
      "End of episode at iteration 13611: \n",
      "\tEpisode reward = 145.0\n",
      "\n",
      "End of episode at iteration 13670: \n",
      "\tEpisode reward = 59.0\n",
      "\n",
      "End of episode at iteration 13705: \n",
      "\tEpisode reward = 35.0\n",
      "\n",
      "End of episode at iteration 13729: \n",
      "\tEpisode reward = 24.0\n",
      "\n",
      "End of episode at iteration 13769: \n",
      "\tEpisode reward = 40.0\n",
      "\n",
      "End of episode at iteration 13787: \n",
      "\tEpisode reward = 18.0\n",
      "\n",
      "End of episode at iteration 13823: \n",
      "\tEpisode reward = 36.0\n",
      "\n",
      "End of episode at iteration 13916: \n",
      "\tEpisode reward = 93.0\n",
      "\n",
      "End of episode at iteration 13948: \n",
      "\tEpisode reward = 32.0\n",
      "\n",
      "End of episode at iteration 13988: \n",
      "\tEpisode reward = 40.0\n",
      "\n",
      "Iteration 14000: \n",
      "\tActor loss = tensor([0.3885]) \n",
      "\tCritic loss = tensor([0.3735])\n",
      "\n",
      "End of episode at iteration 14041: \n",
      "\tEpisode reward = 53.0\n",
      "\n",
      "End of episode at iteration 14099: \n",
      "\tEpisode reward = 58.0\n",
      "\n",
      "End of episode at iteration 14148: \n",
      "\tEpisode reward = 49.0\n",
      "\n",
      "End of episode at iteration 14198: \n",
      "\tEpisode reward = 50.0\n",
      "\n",
      "End of episode at iteration 14272: \n",
      "\tEpisode reward = 74.0\n",
      "\n",
      "End of episode at iteration 14367: \n",
      "\tEpisode reward = 95.0\n",
      "\n",
      "End of episode at iteration 14381: \n",
      "\tEpisode reward = 14.0\n",
      "\n",
      "End of episode at iteration 14401: \n",
      "\tEpisode reward = 20.0\n",
      "\n",
      "End of episode at iteration 14446: \n",
      "\tEpisode reward = 45.0\n",
      "\n",
      "End of episode at iteration 14501: \n",
      "\tEpisode reward = 55.0\n",
      "\n",
      "End of episode at iteration 14516: \n",
      "\tEpisode reward = 15.0\n",
      "\n",
      "End of episode at iteration 14616: \n",
      "\tEpisode reward = 100.0\n",
      "\n",
      "End of episode at iteration 14665: \n",
      "\tEpisode reward = 49.0\n",
      "\n",
      "End of episode at iteration 14731: \n",
      "\tEpisode reward = 66.0\n",
      "\n",
      "End of episode at iteration 14761: \n",
      "\tEpisode reward = 30.0\n",
      "\n",
      "End of episode at iteration 14847: \n",
      "\tEpisode reward = 86.0\n",
      "\n",
      "End of episode at iteration 14864: \n",
      "\tEpisode reward = 17.0\n",
      "\n",
      "End of episode at iteration 14890: \n",
      "\tEpisode reward = 26.0\n",
      "\n",
      "End of episode at iteration 14936: \n",
      "\tEpisode reward = 46.0\n",
      "\n",
      "End of episode at iteration 14993: \n",
      "\tEpisode reward = 57.0\n",
      "\n",
      "Iteration 15000: \n",
      "\tActor loss = tensor([0.1661]) \n",
      "\tCritic loss = tensor([0.6263])\n",
      "\n",
      "End of episode at iteration 15013: \n",
      "\tEpisode reward = 20.0\n",
      "\n",
      "End of episode at iteration 15076: \n",
      "\tEpisode reward = 63.0\n",
      "\n",
      "End of episode at iteration 15116: \n",
      "\tEpisode reward = 40.0\n",
      "\n",
      "End of episode at iteration 15130: \n",
      "\tEpisode reward = 14.0\n",
      "\n",
      "End of episode at iteration 15192: \n",
      "\tEpisode reward = 62.0\n",
      "\n",
      "End of episode at iteration 15239: \n",
      "\tEpisode reward = 47.0\n",
      "\n",
      "End of episode at iteration 15252: \n",
      "\tEpisode reward = 13.0\n",
      "\n",
      "End of episode at iteration 15319: \n",
      "\tEpisode reward = 67.0\n",
      "\n",
      "End of episode at iteration 15362: \n",
      "\tEpisode reward = 43.0\n",
      "\n",
      "End of episode at iteration 15395: \n",
      "\tEpisode reward = 33.0\n",
      "\n",
      "End of episode at iteration 15419: \n",
      "\tEpisode reward = 24.0\n",
      "\n",
      "End of episode at iteration 15438: \n",
      "\tEpisode reward = 19.0\n",
      "\n",
      "End of episode at iteration 15562: \n",
      "\tEpisode reward = 124.0\n",
      "\n",
      "End of episode at iteration 15576: \n",
      "\tEpisode reward = 14.0\n",
      "\n",
      "End of episode at iteration 15650: \n",
      "\tEpisode reward = 74.0\n",
      "\n",
      "End of episode at iteration 15665: \n",
      "\tEpisode reward = 15.0\n",
      "\n",
      "End of episode at iteration 15696: \n",
      "\tEpisode reward = 31.0\n",
      "\n",
      "End of episode at iteration 15723: \n",
      "\tEpisode reward = 27.0\n",
      "\n",
      "End of episode at iteration 15770: \n",
      "\tEpisode reward = 47.0\n",
      "\n",
      "End of episode at iteration 15845: \n",
      "\tEpisode reward = 75.0\n",
      "\n",
      "End of episode at iteration 15892: \n",
      "\tEpisode reward = 47.0\n",
      "\n",
      "End of episode at iteration 15953: \n",
      "\tEpisode reward = 61.0\n",
      "\n",
      "End of episode at iteration 15971: \n",
      "\tEpisode reward = 18.0\n",
      "\n",
      "Iteration 16000: \n",
      "\tActor loss = tensor([1.3152]) \n",
      "\tCritic loss = tensor([2.1384])\n",
      "\n",
      "End of episode at iteration 16033: \n",
      "\tEpisode reward = 62.0\n",
      "\n",
      "End of episode at iteration 16102: \n",
      "\tEpisode reward = 69.0\n",
      "\n",
      "End of episode at iteration 16139: \n",
      "\tEpisode reward = 37.0\n",
      "\n",
      "End of episode at iteration 16198: \n",
      "\tEpisode reward = 59.0\n",
      "\n",
      "End of episode at iteration 16269: \n",
      "\tEpisode reward = 71.0\n",
      "\n",
      "End of episode at iteration 16300: \n",
      "\tEpisode reward = 31.0\n",
      "\n",
      "End of episode at iteration 16373: \n",
      "\tEpisode reward = 73.0\n",
      "\n",
      "End of episode at iteration 16413: \n",
      "\tEpisode reward = 40.0\n",
      "\n",
      "End of episode at iteration 16452: \n",
      "\tEpisode reward = 39.0\n",
      "\n",
      "End of episode at iteration 16512: \n",
      "\tEpisode reward = 60.0\n",
      "\n",
      "End of episode at iteration 16612: \n",
      "\tEpisode reward = 100.0\n",
      "\n",
      "End of episode at iteration 16626: \n",
      "\tEpisode reward = 14.0\n",
      "\n",
      "End of episode at iteration 16643: \n",
      "\tEpisode reward = 17.0\n",
      "\n",
      "End of episode at iteration 16734: \n",
      "\tEpisode reward = 91.0\n",
      "\n",
      "End of episode at iteration 16765: \n",
      "\tEpisode reward = 31.0\n",
      "\n",
      "End of episode at iteration 16915: \n",
      "\tEpisode reward = 150.0\n",
      "\n",
      "End of episode at iteration 16983: \n",
      "\tEpisode reward = 68.0\n",
      "\n",
      "End of episode at iteration 16997: \n",
      "\tEpisode reward = 14.0\n",
      "\n",
      "Iteration 17000: \n",
      "\tActor loss = tensor([0.6558]) \n",
      "\tCritic loss = tensor([0.9863])\n",
      "\n",
      "End of episode at iteration 17101: \n",
      "\tEpisode reward = 104.0\n",
      "\n",
      "End of episode at iteration 17177: \n",
      "\tEpisode reward = 76.0\n",
      "\n",
      "End of episode at iteration 17287: \n",
      "\tEpisode reward = 110.0\n",
      "\n",
      "End of episode at iteration 17364: \n",
      "\tEpisode reward = 77.0\n",
      "\n",
      "End of episode at iteration 17413: \n",
      "\tEpisode reward = 49.0\n",
      "\n",
      "End of episode at iteration 17453: \n",
      "\tEpisode reward = 40.0\n",
      "\n",
      "End of episode at iteration 17495: \n",
      "\tEpisode reward = 42.0\n",
      "\n",
      "End of episode at iteration 17582: \n",
      "\tEpisode reward = 87.0\n",
      "\n",
      "End of episode at iteration 17697: \n",
      "\tEpisode reward = 115.0\n",
      "\n",
      "End of episode at iteration 17748: \n",
      "\tEpisode reward = 51.0\n",
      "\n",
      "End of episode at iteration 17770: \n",
      "\tEpisode reward = 22.0\n",
      "\n",
      "End of episode at iteration 17811: \n",
      "\tEpisode reward = 41.0\n",
      "\n",
      "End of episode at iteration 17863: \n",
      "\tEpisode reward = 52.0\n",
      "\n",
      "End of episode at iteration 17932: \n",
      "\tEpisode reward = 69.0\n",
      "\n",
      "End of episode at iteration 17955: \n",
      "\tEpisode reward = 23.0\n",
      "\n",
      "Iteration 18000: \n",
      "\tActor loss = tensor([0.4491]) \n",
      "\tCritic loss = tensor([0.7780])\n",
      "\n",
      "End of episode at iteration 18024: \n",
      "\tEpisode reward = 69.0\n",
      "\n",
      "End of episode at iteration 18113: \n",
      "\tEpisode reward = 89.0\n",
      "\n",
      "End of episode at iteration 18152: \n",
      "\tEpisode reward = 39.0\n",
      "\n",
      "End of episode at iteration 18190: \n",
      "\tEpisode reward = 38.0\n",
      "\n",
      "End of episode at iteration 18227: \n",
      "\tEpisode reward = 37.0\n",
      "\n",
      "End of episode at iteration 18254: \n",
      "\tEpisode reward = 27.0\n",
      "\n",
      "End of episode at iteration 18291: \n",
      "\tEpisode reward = 37.0\n",
      "\n",
      "End of episode at iteration 18313: \n",
      "\tEpisode reward = 22.0\n",
      "\n",
      "End of episode at iteration 18344: \n",
      "\tEpisode reward = 31.0\n"
     ]
    }
   ],
   "source": [
    "!python MP2_A2C_Becker_Feillard-main/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f266f8-6eb1-48c0-af86-e08918920b70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
